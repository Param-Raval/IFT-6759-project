{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNvR79wCcsZx"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/train/train.En.csv\n",
        "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/test/task_A_En_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32NvsRExc9Ok"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "import nltk\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from string import punctuation\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n",
        "import tensorflow as tf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "DX2weMnr3-8k",
        "outputId": "58752b2b-32e3-434a-ebf5-5cec30bdef31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              tweet  sarcastic  \\\n",
              "0           0  The only thing I got from college is a caffein...          1   \n",
              "1           1  I love it when professors draw a big question ...          1   \n",
              "2           2  Remember the hundred emails from companies whe...          1   \n",
              "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
              "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
              "\n",
              "                                            rephrase  sarcasm  irony  satire  \\\n",
              "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
              "1  I do not like when professors don’t write out ...      1.0    0.0     0.0   \n",
              "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
              "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
              "4  I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0     0.0   \n",
              "\n",
              "   understatement  overstatement  rhetorical_question  \n",
              "0             0.0            0.0                  0.0  \n",
              "1             0.0            0.0                  0.0  \n",
              "2             0.0            0.0                  0.0  \n",
              "3             0.0            0.0                  0.0  \n",
              "4             0.0            0.0                  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-353bd5af-4390-4271-9783-dcaf9fa62321\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>rephrase</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "      <td>College is really difficult, expensive, tiring...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "      <td>I do not like when professors don’t write out ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-353bd5af-4390-4271-9783-dcaf9fa62321')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-353bd5af-4390-4271-9783-dcaf9fa62321 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-353bd5af-4390-4271-9783-dcaf9fa62321');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('/content/train.En.csv')\n",
        "df_test = pd.read_csv('/content/task_A_En_test.csv')\n",
        "df_train = df \n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0BXdM_K0wMF"
      },
      "outputs": [],
      "source": [
        "df=df.dropna(subset=['tweet'])\n",
        "df_test=df_test.dropna(subset=['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wBuNyVN-ZYjF",
        "outputId": "416e6332-a05c-4791-9371-a45e7fdd33d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAREklEQVR4nO3df6xf9V3H8edrBbZFpxS5Ytc2ts4a0xlX5hXwxx/IMigkWjS6QKJUJOlMIHGJGpn/MDdJNG4Sp5Okhm5lURGdc3VBseLULHGjl1kZLSJXtoU2HVxXxjYXMSVv/7ifZt+19/bz7XLP997rfT6Sk3vO+3zOOe/7z33l/LypKiRJOpdXLHcDkqSVz7CQJHUZFpKkLsNCktRlWEiSui5Y7gaGcOmll9aWLVuWuw1JWlUee+yx/6qqqYXW/b8Miy1btjAzM7PcbUjSqpLkc4ut8zKUJKnLsJAkdRkWkqQuw0KS1DVYWCR5VZJHk/xbkiNJfqPVP5DkM0kOt2lHqyfJe5PMJnk8yRtH9rU7ydNt2j1Uz5KkhQ35NNRLwDVV9ZUkFwIfT/I3bd2vVtVfnDH+emBbm64E7gWuTHIJcBcwDRTwWJIDVfXCgL1LkkYMdmZR877SFi9s07k+cbsLuL9t9wng4iQbgOuAg1V1sgXEQWDnUH1Lks426D2LJOuSHAaeZ/4P/ifbqrvbpaZ7kryy1TYCz45sfqzVFqufeaw9SWaSzMzNzS31ryJJa9qgYVFVL1fVDmATcEWS7wPeDnwv8IPAJcCvLdGx9lbVdFVNT00t+AKiJOkbNJE3uKvqi0k+Buysqne38ktJ3g/8Sls+Dmwe2WxTqx0Hrj6j/o+DNrxEfuBX71/uFiStEo/9zi3L3cI5Dfk01FSSi9v8q4E3A//e7kOQJMCNwBNtkwPALe2pqKuAF6vqBPAwcG2S9UnWA9e2miRpQoY8s9gA7E+yjvlQerCqPprkH5JMAQEOA7/Yxj8E3ADMAl8FbgWoqpNJ3gUcauPeWVUnB+xbknSGwcKiqh4HLl+gfs0i4wu4fZF1+4B9S9qgJGlsvsEtSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1DRYWSV6V5NEk/5bkSJLfaPWtST6ZZDbJnyW5qNVf2ZZn2/otI/t6e6s/leS6oXqWJC1syDOLl4BrquoNwA5gZ5KrgN8G7qmq7wZeAG5r428DXmj1e9o4kmwHbgJeD+wE/jDJugH7liSdYbCwqHlfaYsXtqmAa4C/aPX9wI1tfldbpq1/U5K0+gNV9VJVfQaYBa4Yqm9J0tkGvWeRZF2Sw8DzwEHgP4EvVtWpNuQYsLHNbwSeBWjrXwS+bbS+wDaSpAkYNCyq6uWq2gFsYv5s4HuHOlaSPUlmkszMzc0NdRhJWpMm8jRUVX0R+BjwQ8DFSS5oqzYBx9v8cWAzQFv/rcAXRusLbDN6jL1VNV1V01NTU0P8GpK0Zg35NNRUkovb/KuBNwNPMh8aP92G7QY+0uYPtGXa+n+oqmr1m9rTUluBbcCjQ/UtSTrbBf0h37ANwP725NIrgAer6qNJjgIPJPlN4F+B+9r4+4APJpkFTjL/BBRVdSTJg8BR4BRwe1W9PGDfkqQzDBYWVfU4cPkC9WdY4Gmmqvof4GcW2dfdwN1L3aMkaTy+wS1J6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkrsHCIsnmJB9LcjTJkSS/1OrvSHI8yeE23TCyzduTzCZ5Ksl1I/WdrTab5M6hepYkLeyCAfd9CvjlqvpUktcAjyU52NbdU1XvHh2cZDtwE/B64LXA3yf5nrb6fcCbgWPAoSQHqurogL1LkkYMFhZVdQI40ea/nORJYOM5NtkFPFBVLwGfSTILXNHWzVbVMwBJHmhjDQtJmpCJ3LNIsgW4HPhkK92R5PEk+5Ksb7WNwLMjmx1rtcXqZx5jT5KZJDNzc3NL/StI0po2eFgk+WbgQ8DbqupLwL3A64AdzJ95vGcpjlNVe6tquqqmp6amlmKXkqRmyHsWJLmQ+aD446r6S4Cqem5k/R8BH22Lx4HNI5tvajXOUZckTcCQT0MFuA94sqp+d6S+YWTYTwJPtPkDwE1JXplkK7ANeBQ4BGxLsjXJRczfBD8wVN+SpLMNeWbxI8DPAZ9OcrjVfh24OckOoIDPAm8FqKojSR5k/sb1KeD2qnoZIMkdwMPAOmBfVR0ZsG9J0hmGfBrq40AWWPXQOba5G7h7gfpD59pOkjQs3+CWJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUtdgYZFkc5KPJTma5EiSX2r1S5IcTPJ0+7m+1ZPkvUlmkzye5I0j+9rdxj+dZPdQPUuSFjbkmcUp4JerajtwFXB7ku3AncAjVbUNeKQtA1wPbGvTHuBemA8X4C7gSuAK4K7TASNJmozBwqKqTlTVp9r8l4EngY3ALmB/G7YfuLHN7wLur3mfAC5OsgG4DjhYVSer6gXgILBzqL4lSWcbKyySPDJO7RzbbwEuBz4JXFZVJ9qqzwOXtfmNwLMjmx1rtcXqZx5jT5KZJDNzc3PjtiZJGsM5wyLJq9ploEuTrG/3Gy5pf/zP+oO9yD6+GfgQ8Laq+tLouqoqoL6x1r9eVe2tqumqmp6amlqKXUqSmgs6698KvA14LfAYkFb/EvAHvZ0nuZD5oPjjqvrLVn4uyYaqOtEuMz3f6seBzSObb2q148DVZ9T/sXdsSdLSOeeZRVX9XlVtBX6lqr6rqra26Q1Vdc6wSBLgPuDJqvrdkVUHgNNPNO0GPjJSv6U9FXUV8GK7XPUwcG07s1kPXNtqkqQJ6Z1ZAFBVv5/kh4Eto9tU1f3n2OxHgJ8DPp3kcKv9OvBbwINJbgM+B7ylrXsIuAGYBb4K3NqOcTLJu4BDbdw7q+rkOH1LkpbGWGGR5IPA64DDwMutXMCiYVFVH+drl63O9KYFxhdw+yL72gfsG6dXSdLSGyssgGlge/uDLklaY8Z9z+IJ4DuGbESStHKNe2ZxKXA0yaPAS6eLVfUTg3QlSVpRxg2LdwzZhCRpZRv3aah/GroRSdLKNe7TUF/ma29aXwRcCPx3VX3LUI1JklaOcc8sXnN6vr1st4v5L8lKktaA8/7qbPsq7F8x/zVYSdIaMO5lqJ8aWXwF8+9d/M8gHUmSVpxxn4b68ZH5U8Bnmb8UJUlaA8a9Z3Hr0I1Iklaucf/50aYkH07yfJs+lGTT0M1JklaGcW9wv5/5T4i/tk1/3WqSpDVg3LCYqqr3V9WpNn0A8N/RSdIaMW5YfCHJzyZZ16afBb4wZGOSpJVj3LD4Beb/SdHngRPATwM/P1BPkqQVZtxHZ98J7K6qFwCSXAK8m/kQkST9PzfumcX3nw4KmP9Xp8Dlw7QkSVppxg2LVyRZf3qhnVmMe1YiSVrlxv2D/x7gX5L8eVv+GeDuYVqSJK00477BfX+SGeCaVvqpqjo6XFuSpJVk7K/OVtXRqvqDNnWDIsm+9rb3EyO1dyQ5nuRwm24YWff2JLNJnkpy3Uh9Z6vNJrnzfH45SdLSOO9PlJ+HDwA7F6jfU1U72vQQQJLtwE3A69s2f3j6nQ7gfcD1wHbg5jZWkjRBg92krqp/TrJlzOG7gAeq6iXgM0lmgSvautmqegYgyQNtrJfAJGmChjyzWMwdSR5vl6lOP2G1EXh2ZMyxVlusfpYke5LMJJmZm5sbom9JWrMmHRb3Aq8DdjD/Jvh7lmrHVbW3qqaranpqys9WSdJSmui7ElX13On5JH8EfLQtHgc2jwzd1Gqcoy5JmpCJnlkk2TCy+JPA6SelDgA3JXllkq3ANuBR4BCwLcnWJBcxfxP8wCR7liQNeGaR5E+Bq4FLkxwD7gKuTrIDKOb/NetbAarqSJIHmb9xfQq4vapebvu5A3gYWAfsq6ojQ/UsSVrYkE9D3bxA+b5zjL+bBd4Kb4/XPrSErUmSztNyPA0lSVplDAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrsLBIsi/J80meGKldkuRgkqfbz/WtniTvTTKb5PEkbxzZZncb/3SS3UP1K0la3JBnFh8Adp5RuxN4pKq2AY+0ZYDrgW1t2gPcC/PhAtwFXAlcAdx1OmAkSZMzWFhU1T8DJ88o7wL2t/n9wI0j9ftr3ieAi5NsAK4DDlbVyap6ATjI2QEkSRrYpO9ZXFZVJ9r854HL2vxG4NmRccdabbH6WZLsSTKTZGZubm5pu5akNW7ZbnBXVQG1hPvbW1XTVTU9NTW1VLuVJDH5sHiuXV6i/Xy+1Y8Dm0fGbWq1xeqSpAmadFgcAE4/0bQb+MhI/Zb2VNRVwIvtctXDwLVJ1rcb29e2miRpgi4YasdJ/hS4Grg0yTHmn2r6LeDBJLcBnwPe0oY/BNwAzAJfBW4FqKqTSd4FHGrj3llVZ940lyQNbLCwqKqbF1n1pgXGFnD7IvvZB+xbwtYkSefJN7glSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1LUsYZHks0k+neRwkplWuyTJwSRPt5/rWz1J3ptkNsnjSd64HD1L0lq2nGcWP1ZVO6pqui3fCTxSVduAR9oywPXAtjbtAe6deKeStMatpMtQu4D9bX4/cONI/f6a9wng4iQblqE/SVqzlissCvi7JI8l2dNql1XViTb/eeCyNr8ReHZk22Ot9nWS7Ekyk2Rmbm5uqL4laU26YJmO+6NVdTzJtwMHk/z76MqqqiR1Pjusqr3AXoDp6enz2laSdG7LcmZRVcfbz+eBDwNXAM+dvrzUfj7fhh8HNo9svqnVJEkTMvGwSPJNSV5zeh64FngCOADsbsN2Ax9p8weAW9pTUVcBL45crpIkTcByXIa6DPhwktPH/5Oq+tskh4AHk9wGfA54Sxv/EHADMAt8Fbh18i1L0to28bCoqmeANyxQ/wLwpgXqBdw+gdYkSYtYSY/OSpJWKMNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqWjVhkWRnkqeSzCa5c7n7kaS1ZFWERZJ1wPuA64HtwM1Jti9vV5K0dqyKsACuAGar6pmq+l/gAWDXMvckSWvGBcvdwJg2As+OLB8DrhwdkGQPsKctfiXJUxPqTTpflwL/tdxNaGXJu3cvdwsA37nYitUSFl1VtRfYu9x9SD1JZqpqern7kM7HarkMdRzYPLK8qdUkSROwWsLiELAtydYkFwE3AQeWuSdJWjNWxWWoqjqV5A7gYWAdsK+qjixzW9I3ysulWnVSVcvdgyRphVstl6EkScvIsJAkdRkW0oT4yRqtZt6zkCagfbLmP4A3M/9S6SHg5qo6uqyNSWPyzEKaDD9Zo1XNsJAmY6FP1mxcpl6k82ZYSJK6DAtpMvxkjVY1w0KaDD9Zo1VtVXzuQ1rt/GSNVjsfnZUkdXkZSpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdf0fH6y1ysbamm4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(df['sarcastic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeG_5S8Lv1iP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3cqauTxvBu6"
      },
      "source": [
        "#### Len of tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "o4r-BFdxuHQv",
        "outputId": "202f1499-26b3-4f0a-8a62-62acba8ae596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([291., 716., 603., 456., 201., 123.,  90.,  98.,  20.,   2.]),\n",
              " array([  2. ,  38.3,  74.6, 110.9, 147.2, 183.5, 219.8, 256.1, 292.4,\n",
              "        328.7, 365. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAEvCAYAAADW/SmEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfJklEQVR4nO3df6xndX3n8edrGcBGjYDcnbAzww62szW0WQd6l8VojIXY8qPp0MSymEanhmSaXdxo2k07tslqk5rgZivVpEt3uliHrhUpapgI2y0FGtM/RAdE5EepVxzCTAZm6g/UmuqC7/3j+xn4Otw79/f9fs7c5yP55nvO55zv977mcL0fX/ec77mpKiRJkiRJffoXkw4gSZIkSZqbpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkiRJkjq2YdIBAM4+++zaunXrpGNIktbA/fff/49VNTXpHEPhHClJ68OJ5sd5S1uSlwGfA05v+99WVe9Lch5wC/Bq4H7g7VX1wySnAzcDPwd8A/gPVXXgRF9j69at7N+/fxH/JEnSUCV5ctIZhsQ5UpLWhxPNjwu5PPIHwCVV9TpgO3BZkouBDwI3VNVPAd8Crm37Xwt8q43f0PaTJEmSJC3BvKWtRr7XVk9tjwIuAW5r43uBq9ryjrZO235pkqxUYEmSJElaTxZ0I5IkpyR5EDgC3AV8Dfh2VT3XdjkIbGrLm4CnANr2ZxldQilJkiRJWqQFlbaqer6qtgObgYuA1y73CyfZlWR/kv1Hjx5d7ttJkiRJ0klpUbf8r6pvA/cCrwfOSHLsRiabgUNt+RCwBaBtfxWjG5Ic/157qmq6qqanpryJmCRJkiTNZt7SlmQqyRlt+SeAtwCPMSpvb2277QRub8v72jpt+z1VVSuYWZIkSZLWjYX8nbZzgL1JTmFU8m6tqs8meRS4JckfAF8Cbmr73wT8eZIZ4JvANauQW5IkSZLWhXlLW1U9BFwwy/gTjD7fdvz4PwO/uiLpJEmSJGmdW9Rn2iRJkiRJa8vSJkmSJEkds7RJkiRJUscWciMSLdLW3XdMOsILDlx/5aQjSJL0gl7mSOdHSUPimTZJkiRJ6pilTZKkJUry00keHHt8J8l7kpyV5K4kX23PZ7b9k+QjSWaSPJTkwkn/GyRJ/bO0SZK0RFX1eFVtr6rtwM8B3wc+A+wG7q6qbcDdbR3gcmBbe+wCblzz0JKkwbG0SZK0Mi4FvlZVTwI7gL1tfC9wVVveAdxcI58HzkhyzponlSQNiqVNkqSVcQ3wiba8saoOt+WngY1teRPw1NhrDrYxSZLmZGmTJGmZkpwG/DLwl8dvq6oCapHvtyvJ/iT7jx49ukIpJUlDZWmTJGn5LgceqKpn2vozxy57bM9H2vghYMvY6za3sR9TVXuqarqqpqemplYxtiRpCCxtkiQt39t48dJIgH3Azra8E7h9bPwd7S6SFwPPjl1GKUnSrPzj2pIkLUOSlwNvAX5jbPh64NYk1wJPAle38TuBK4AZRneafOcaRpUkDZSlTZKkZaiqfwJefdzYNxjdTfL4fQu4bo2iSZJOEl4eKUmSJEkds7RJkiRJUscsbZIkSZLUMUubJEmSJHXM0iZJkiRJHbO0SZIkSVLHLG2SJEmS1DFLmyRJkiR1zNImSZIkSR2ztEmSJElSxyxtkiRJktQxS5skSZIkdczSJkmSJEkds7RJkiRJUscsbZIkSZLUMUubJEmSJHXM0iZJkiRJHbO0SZIkSVLHLG2SJEmS1DFLmyRJkiR1zNImSZIkSR2ztEmSJElSx+YtbUm2JLk3yaNJHkny7jb+/iSHkjzYHleMvea9SWaSPJ7kF1fzHyBJkiRJJ7MNC9jnOeC3quqBJK8E7k9yV9t2Q1X99/Gdk5wPXAP8DPCvgL9J8m+q6vmVDC5JkiRJ68G8Z9qq6nBVPdCWvws8Bmw6wUt2ALdU1Q+q6uvADHDRSoSVJEmSpPVmUZ9pS7IVuAC4rw29K8lDST6a5Mw2tgl4auxlB5ml5CXZlWR/kv1Hjx5dfHJJkiRJWgcWXNqSvAL4FPCeqvoOcCPwk8B24DDwh4v5wlW1p6qmq2p6ampqMS+VJEmSpHVjQaUtyamMCtvHq+rTAFX1TFU9X1U/Av6UFy+BPARsGXv55jYmSdJJJ8kZSW5L8vdJHkvy+iRnJbkryVfb85lt3yT5SLtZ10NJLpx0fklS/xZy98gANwGPVdWHxsbPGdvtV4CH2/I+4Jokpyc5D9gGfGHlIkuS1JUPA39VVa8FXsfos9+7gburahtwd1sHuJzRvLgN2MXoqhVJkk5oIXePfAPwduArSR5sY78LvC3JdqCAA8BvAFTVI0luBR5ldOfJ67xzpCTpZJTkVcCbgF8HqKofAj9MsgN4c9ttL/C3wO8wulnXzVVVwOfbWbpzqurwGkeXJA3IvKWtqv4OyCyb7jzBaz4AfGAZuSRJGoLzgKPAnyV5HXA/8G5g41gRexrY2JbnulmXpW2Nbd19x6QjvODA9VdOOoKkzi3q7pGSJOnHbAAuBG6sqguAf+LFSyEBaGfVajFv6h2WJUnjLG2SJC3dQeBgVR37Uzi3MSpxzxz77Hd7PtK2L+hmXd5hWZI0ztImSdISVdXTwFNJfroNXcroM937gJ1tbCdwe1veB7yj3UXyYuBZP88mSZrPQm5EIkmS5vafgY8nOQ14Angno1+K3prkWuBJ4Oq2753AFcAM8P22ryRJJ2RpkyRpGarqQWB6lk2XzrJvAdetdiZJ0snFyyMlSZIkqWOWNkmSJEnqmKVNkiRJkjpmaZMkSZKkjlnaJEmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnq2IZJB9Dq2rr7jklHAODA9VdOOoIkSZI0SJ5pkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkiRJkjpmaZMkSZKkjlnaJEmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRpGZIcSPKVJA8m2d/GzkpyV5Kvtucz23iSfCTJTJKHklw42fSSpCGwtEmStHw/X1Xbq2q6re8G7q6qbcDdbR3gcmBbe+wCblzzpJKkwbG0SZK08nYAe9vyXuCqsfGba+TzwBlJzplAPknSgMxb2pJsSXJvkkeTPJLk3W3cSz8kSYIC/jrJ/Ul2tbGNVXW4LT8NbGzLm4Cnxl57sI1JkjSnhZxpew74rao6H7gYuC7J+XjphyRJAG+sqgsZzX/XJXnT+MaqKkbFbsGS7EqyP8n+o0ePrmBUSdIQzVvaqupwVT3Qlr8LPMbot4Je+iFJWveq6lB7PgJ8BrgIeObY3Neej7TdDwFbxl6+uY0d/557qmq6qqanpqZWM74kaQAW9Zm2JFuBC4D78NIPSdI6l+TlSV55bBn4BeBhYB+ws+22E7i9Le8D3tE+SnAx8OzYXCpJ0qw2LHTHJK8APgW8p6q+k+SFbVVVSRZ96Qejyyc599xzF/NSSZJ6sRH4TJsTNwB/UVV/leSLwK1JrgWeBK5u+98JXAHMAN8H3rn2kSVJQ7Og0pbkVEaF7eNV9ek2/EySc6rq8FIv/QD2AExPTy+q8EmS1IOqegJ43Szj3wAunWW8gOvWIJok6SSykLtHBrgJeKyqPjS2yUs/JEmSJGmVLeRM2xuAtwNfSfJgG/td4Hq89EOSJEmSVtW8pa2q/g7IHJu99EOSJEmSVtGi7h4pSZIkSVpbljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOzfvHtSVJkrR6tu6+Y9IRADhw/ZWTjiBpDp5pkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkiRJkjpmaZMkSZKkjlnaJEmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkqRlSHJKki8l+WxbPy/JfUlmknwyyWlt/PS2PtO2b51ocEnSYFjaJElanncDj42tfxC4oap+CvgWcG0bvxb4Vhu/oe0nSdK8LG2SJC1Rks3AlcD/ausBLgFua7vsBa5qyzvaOm37pW1/SZJOyNImSdLS/RHw28CP2vqrgW9X1XNt/SCwqS1vAp4CaNufbftLknRCljZJkpYgyS8BR6rq/lV4711J9ifZf/To0ZV+e0nSwFjaJElamjcAv5zkAHALo8siPwyckWRD22czcKgtHwK2ALTtrwK+MdsbV9WeqpququmpqanV+xdIkgbB0iZJ0hJU1XuranNVbQWuAe6pql8D7gXe2nbbCdzelve1ddr2e6qq1jCyJGmgLG2SJK2s3wF+M8kMo8+s3dTGbwJe3cZ/E9g9oXySpIHZMP8ukiTpRKrqb4G/bctPABfNss8/A7+6psEkSScFz7RJkiRJUscsbZIkSZLUMUubJEmSJHVs3tKW5KNJjiR5eGzs/UkOJXmwPa4Y2/beJDNJHk/yi6sVXJIkSZLWg4WcafsYcNks4zdU1fb2uBMgyfmMbnv8M+01/yPJKSsVVpIkSZLWm3lLW1V9DvjmAt9vB3BLVf2gqr4OzDDLHbQkSZIkSQuznM+0vSvJQ+3yyTPb2CbgqbF9Draxl0iyK8n+JPuPHj26jBiSJEmSdPJaamm7EfhJYDtwGPjDxb5BVe2pqumqmp6amlpiDEmSJEk6uS2ptFXVM1X1fFX9CPhTXrwE8hCwZWzXzW1MkiRJkrQESyptSc4ZW/0V4NidJfcB1yQ5Pcl5wDbgC8uLKEmSJEnr14b5dkjyCeDNwNlJDgLvA96cZDtQwAHgNwCq6pEktwKPAs8B11XV86uSXJIkSZLWgXlLW1W9bZbhm06w/weADywnlCRJkiRpZDl3j5QkSZIkrTJLmyRJkiR1zNImSZIkSR2ztEmSJElSxyxtkiRJktQxS5skSZIkdczSJkmSJEkds7RJkiRJUscsbZIkSZLUsQ2TDqD1YevuOyYd4QUHrr9y0hEkSZKkBfNMmyRJkiR1zNImSZIkSR2ztEmSJElSxyxtkiRJktQxS5skSZIkdczSJkmSJEkds7RJkrRESV6W5AtJvpzkkSS/38bPS3Jfkpkkn0xyWhs/va3PtO1bJ/oPkCQNgqVNkqSl+wFwSVW9DtgOXJbkYuCDwA1V9VPAt4Br2/7XAt9q4ze0/SRJOiFLmyRJS1Qj32urp7ZHAZcAt7XxvcBVbXlHW6dtvzRJ1iatJGmoLG2SJC1DklOSPAgcAe4CvgZ8u6qea7scBDa15U3AUwBt+7PAq2d5z11J9ifZf/To0VX+F0iSemdpkyRpGarq+araDmwGLgJeuwLvuaeqpqtqempqarlvJ0kauA2TDrBStu6+Y9IRJEnrWFV9O8m9wOuBM5JsaGfTNgOH2m6HgC3AwSQbgFcB35hIYEnSYHimTZKkJUoyleSMtvwTwFuAx4B7gbe23XYCt7flfW2dtv2eqqo1CyxJGqST5kybJEkTcA6wN8kpjH4RemtVfTbJo8AtSf4A+BJwU9v/JuDPk8wA3wSuWYuQXo0iScNmaZMkaYmq6iHgglnGn2D0+bbjx/8Z+NU1iCZJOol4eaQkSZIkdczSJkmSJEkds7RJkiRJUscsbZIkSZLUMUubJEmSJHXM0iZJkiRJHbO0SZIkSVLHLG2SJEmS1DFLmyRJkiR1zNImSZIkSR2bt7Ql+WiSI0keHhs7K8ldSb7ans9s40nykSQzSR5KcuFqhpckSZKkk91CzrR9DLjsuLHdwN1VtQ24u60DXA5sa49dwI0rE1OSJEmS1qd5S1tVfQ745nHDO4C9bXkvcNXY+M018nngjCTnrFBWSZIkSVp3lvqZto1VdbgtPw1sbMubgKfG9jvYxiRJkiRJS7DsG5FUVQG12Ncl2ZVkf5L9R48eXW4MSZIkSTopLbW0PXPsssf2fKSNHwK2jO23uY29RFXtqarpqpqemppaYgxJkiRJOrkttbTtA3a25Z3A7WPj72h3kbwYeHbsMkpJkiRJ0iJtmG+HJJ8A3gycneQg8D7geuDWJNcCTwJXt93vBK4AZoDvA+9chcySJEmStG7MW9qq6m1zbLp0ln0LuG65oSRJkiRJI8u+EYkkSZIkafVY2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkiRJkjpmaZMkaYmSbElyb5JHkzyS5N1t/KwkdyX5ans+s40nyUeSzCR5KMmFk/0XSJKGwNImSdLSPQf8VlWdD1wMXJfkfGA3cHdVbQPubusAlwPb2mMXcOPaR5YkDY2lTZKkJaqqw1X1QFv+LvAYsAnYAextu+0FrmrLO4Cba+TzwBlJzlnb1JKkodkw6QCSJJ0MkmwFLgDuAzZW1eG26WlgY1veBDw19rKDbezw2BhJdjE6E8e55567eqGlMVt33zHpCC84cP2Vk44gdcUzbZIkLVOSVwCfAt5TVd8Z31ZVBdRi3q+q9lTVdFVNT01NrWBSSdIQWdokSVqGJKcyKmwfr6pPt+Fnjl322J6PtPFDwJaxl29uY5IkzcnSJknSEiUJcBPwWFV9aGzTPmBnW94J3D42/o52F8mLgWfHLqOUJGlWfqZNkqSlewPwduArSR5sY78LXA/cmuRa4Eng6rbtTuAKYAb4PvDONU0rSRokS5skSUtUVX8HZI7Nl86yfwHXrWooSdJJx8sjJUmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnqmKVNkiRJkjpmaZMkSZKkjlnaJEmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOrZhOS9OcgD4LvA88FxVTSc5C/gksBU4AFxdVd9aXkxJkiRJWp9W4kzbz1fV9qqabuu7gburahtwd1uXJEmSJC3BalweuQPY25b3AletwteQJEmSpHVhWZdHAgX8dZIC/mdV7QE2VtXhtv1pYONsL0yyC9gFcO655y4zhiRJkk4WW3ffMekILzhw/ZWTjiAtu7S9saoOJfmXwF1J/n58Y1VVK3Qv0QreHoDp6elZ95EkSZKk9W5Zl0dW1aH2fAT4DHAR8EyScwDa85HlhpQkSZKk9WrJpS3Jy5O88tgy8AvAw8A+YGfbbSdw+3JDSpIkSdJ6tZzLIzcCn0ly7H3+oqr+KskXgVuTXAs8CVy9/JjSyunlOnmvkZckSdJCLLm0VdUTwOtmGf8GcOlyQkmSNARJPgr8EnCkqn62jc3690oz+i3nh4ErgO8Dv15VD0wityRpWFbjlv+SJK0XHwMuO25srr9XejmwrT12ATeuUUZJ0sBZ2iRJWqKq+hzwzeOG5/p7pTuAm2vk88AZx27cJUnSiVjaJElaWXP9vdJNwFNj+x1sY5IkndBy/06bJEmaw4n+XumJJNnF6BJKzj333BXPJWl4ermRGngztUnwTJskSStrrr9XegjYMrbf5jb2ElW1p6qmq2p6ampqVcNKkvpnaZMkaWXN9fdK9wHvyMjFwLNjl1FKkjQnL4+UJGmJknwCeDNwdpKDwPuA65n975Xeyeh2/zOMbvn/zjUPLGnRerosUeuXpU2SpCWqqrfNseklf6+0qgq4bnUTSZJORl4eKUmSJEkds7RJkiRJUscsbZIkSZLUMUubJEmSJHXM0iZJkiRJHbO0SZIkSVLHLG2SJEmS1DFLmyRJkiR1zNImSZIkSR3bMOkA0nq1dfcdk47wggPXXznpCJIkSZqDZ9okSZIkqWOeaZPkWT9JkqSOeaZNkiRJkjpmaZMkSZKkjlnaJEmSJKljljZJkiRJ6pilTZIkSZI6ZmmTJEmSpI5Z2iRJkiSpY5Y2SZIkSeqYpU2SJEmSOmZpkyRJkqSOWdokSZIkqWOWNkmSJEnq2IZJB5AkSZI0HFt33zHpCAAcuP7KSUdYM5Y2SV1xIpAkSfpxXh4pSZIkSR1btdKW5LIkjyeZSbJ7tb6OJElD4vwoSVqsVSltSU4B/hi4HDgfeFuS81fja0mSNBTOj5KkpVitM20XATNV9URV/RC4BdixSl9LkqShcH6UJC3aat2IZBPw1Nj6QeDfr9LXkqQV18sNUXrizVlWhPOjJK2Qnubq1Z4jJ3b3yCS7gF1t9XtJHp/nJWcD/7i6qVacmVff0PLC8DIPLS8ML/Mg8uaDP7a6nMz/etlhTnJLmCPnMojvrRMYcv4hZwfzT9KQs8M6zX/cHLlUc86Pq1XaDgFbxtY3t7EXVNUeYM9C3zDJ/qqaXpl4a8PMq29oeWF4mYeWF4aXeWh5YZiZOzHv/AiLnyPnMvT/TkPOP+TsYP5JGnJ2MP9qWa3PtH0R2JbkvCSnAdcA+1bpa0mSNBTOj5KkRVuVM21V9VySdwH/FzgF+GhVPbIaX0uSpKFwfpQkLcWqfaatqu4E7lzBt1z2ZSITYObVN7S8MLzMQ8sLw8s8tLwwzMxdWIX58USG/t9pyPmHnB3MP0lDzg7mXxWpqklnkCRJkiTNYbU+0yZJkiRJWgGDKG1JLkvyeJKZJLsnnWcuSQ4k+UqSB5Psb2NnJbkryVfb85kTzPfRJEeSPDw2Nmu+jHykHfOHklzYUeb3JznUjvODSa4Y2/belvnxJL84gbxbktyb5NEkjyR5dxvv9jifIHOXxznJy5J8IcmXW97fb+PnJbmv5fpku8kDSU5v6zNt+9a1zDtP5o8l+frYMd7exif+fdFynJLkS0k+29a7PcZ6qaHMncf0Poceb4hz6rihza/jhjjXLjB/98d/iHPwAvN3PR8DUFVdPxh9UPtrwGuA04AvA+dPOtccWQ8AZx839t+A3W15N/DBCeZ7E3Ah8PB8+YArgP8DBLgYuK+jzO8H/sss+57fvj9OB85r3zenrHHec4AL2/IrgX9oubo9zifI3OVxbsfqFW35VOC+duxuBa5p438C/Me2/J+AP2nL1wCfnMAxnivzx4C3zrL/xL8vWo7fBP4C+Gxb7/YY+3jJf7vBzJ1jmQ/Q8Rw6S97BzakLyN/lz/1Z8gxurl1g/u6P/wnms0HMDyfI/zE6no+rahBn2i4CZqrqiar6IXALsGPCmRZjB7C3Le8FrppUkKr6HPDN44bnyrcDuLlGPg+ckeScNQk6Zo7Mc9kB3FJVP6iqrwMzjL5/1kxVHa6qB9ryd4HHgE10fJxPkHkuEz3O7Vh9r62e2h4FXALc1saPP8bHjv1twKVJsjZpR06QeS4T/75Ishm4EvhfbT10fIz1EkOfO4/pZg493hDn1HFDm1/HDXGuHTe0eXfcEOfgcUOcj48ZQmnbBDw1tn6QE39jT1IBf53k/iS72tjGqjrclp8GNk4m2pzmytf7cX9XO0390bHLZbrK3C4BuIDRb3EGcZyPywydHueMLtt7EDgC3MXot47frqrnZsn0Qt62/Vng1WuZF16auaqOHeMPtGN8Q5LTj8/cTOL74o+A3wZ+1NZfTefHWD+mh++hxRriHHq8Qfysn0eXP/fnMsS5dtxQ5t1xQ5yDxw1wPgaGUdqG5I1VdSFwOXBdkjeNb6zRedZub9fZe74xNwI/CWwHDgN/ONE0s0jyCuBTwHuq6jvj23o9zrNk7vY4V9XzVbUd2Mzot42vnWyi+R2fOcnPAu9llP3fAWcBvzO5hC9K8kvAkaq6f9JZtK4Meg493tDyNt3+3J/NEOfacUOad8cNcQ4eN6T5eNwQStshYMvY+uY21p2qOtSejwCfYfSN/Myx06jt+cjkEs5qrnzdHveqeqb9D+5HwJ/y4iUCXWROciqjH8Ifr6pPt+Guj/NsmXs/zgBV9W3gXuD1jC5ZOPa3J8czvZC3bX8V8I21TfqiscyXtUtkqqp+APwZ/RzjNwC/nOQAo8vqLgE+zECOsYDJfw8t2kDn0ON1/bN+PkP4uX/MEOfacUOdd8cNcQ4eN5D5+AVDKG1fBLa1u9KcxuhDjPsmnOklkrw8ySuPLQO/ADzMKOvOtttO4PbJJJzTXPn2Ae9od825GHh27JKDiTruWuJfYXScYZT5mnanovOAbcAX1jhbgJuAx6rqQ2Obuj3Oc2Xu9TgnmUpyRlv+CeAtjD4PcC/w1rbb8cf42LF/K3BP+w3smpkj89+P/Z+LMLr+f/wYT+z7oqreW1Wbq2oro5+591TVr9HxMdZLDGLuPGbAc+jxuv1ZvxC9/tw/3hDn2nFDm3fHDXEOHje0+fjH1ATv4LLQB6M7t/wDo2tmf2/SeebI+BpGd/b5MvDIsZyMrtu9G/gq8DfAWRPM+AlGp9v/H6Nrcq+dKx+ju+T8cTvmXwGmO8r85y3TQ4z+x3TO2P6/1zI/Dlw+gbxvZHQ5xkPAg+1xRc/H+QSZuzzOwL8FvtRyPQz81zb+GkaT2Azwl8DpbfxlbX2mbX/NBI7xXJnvacf4YeB/8+IdrSb+fTGW/c28ePfIbo+xj1n/23U/d45l7X4OnSXz4ObUBeTv8uf+LNkHN9cuMH/3x/8E89kg5ocT5O9+Pk4LJEmSJEnq0BAuj5QkSZKkdcvSJkmSJEkds7RJkiRJUscsbZIkSZLUMUubJEmSJHXM0iZJkiRJHbO0SZIkSVLHLG2SJEmS1LH/D8vfr6dXhi29AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
        "ax[0].hist(df[df['sarcastic']==1]['tweet'].str.len())\n",
        "ax[1].hist(df[df['sarcastic']==0]['tweet'].str.len())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "FVpMiZsFvEhg",
        "outputId": "4acb23ef-2bc6-4418-ce43-8d419c51ea85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([262., 637., 581., 444., 274., 155., 100.,  81.,  50.,  16.]),\n",
              " array([ 1.,  7., 13., 19., 25., 31., 37., 43., 49., 55., 61.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
        "ax[0].hist(df[df['sarcastic']==1]['tweet'].str.split().map(lambda x: len(x)))\n",
        "ax[1].hist(df[df['sarcastic']==0]['tweet'].str.split().map(lambda x: len(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v_hNlEJvEb-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCXI6bIGX0LZ"
      },
      "source": [
        "### Frequency Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ewafRjTXzXj",
        "outputId": "415e79b3-4aeb-4720-abbb-e544c9ba39b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT8ob8BWxFpu"
      },
      "outputs": [],
      "source": [
        "tokens = df['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_test = df_test['text'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pitNpuHzWuG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "xtrain_bow = bow_vectorizer.fit_transform(tokens)\n",
        "xtest_bow = bow_vectorizer.transform(tokens_test)\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(tokens)\n",
        "xtest_tfidf= tfidf_vectorizer.transform(tokens_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYa8eIKr5s1n",
        "outputId": "12b310c4-7779-4322-ce24-2d7b6e5c27a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3467, 1000), (1400, 1000))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "xtrain_tfidf.shape, xtest_tfidf.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMNZS6rrXpt8"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFqxuQGV2Cg3"
      },
      "outputs": [],
      "source": [
        "tokens = [val.split() for val in tokens]\n",
        "tokens_test = [val.split() for val in tokens_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSwV7YKc2aBZ",
        "outputId": "15fdb874-84c4-49eb-b190-231f10471654"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3467, 1400)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(tokens), len(tokens_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv5p8i3h00ZK",
        "outputId": "d8a9f662-3c11-4277-dc6f-99e9a0b0bab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1184824, 1376250)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import gensim\n",
        "\n",
        "w2v_model = gensim.models.Word2Vec(\n",
        "            tokens,\n",
        "            vector_size=300, # desired no. of features/independent variables\n",
        "            window=5, # context window size\n",
        "            min_count=0, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            seed = 42)\n",
        "\n",
        "w2v_model.train(tokens, total_examples= len(tokens), epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzhaPs-w4QYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ab1637-25ff-46df-d440-05d61002822d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-c7757d71a30b>:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  w2v_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ],
      "source": [
        "w2v_model.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQjqG8aC4vBF"
      },
      "outputs": [],
      "source": [
        "words = set(w2v_model.wv.index_to_key)\n",
        "xtrain_w2v = np.array([np.mean(np.nan_to_num(np.array([w2v_model.wv[i] if i in words else np.zeros((300,)) for i in ls], dtype=object)), axis=0)\n",
        "                         for ls in tokens], dtype=object)\n",
        "xtest_w2v = np.array([np.mean(np.nan_to_num(np.array([w2v_model.wv[i] if i in words else np.zeros((300,)) for i in ls ], dtype=object)), axis=0)\n",
        "                         for ls in tokens_test], dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MJ43lb1XuG1",
        "outputId": "355109b7-494e-4ffc-e3e0-2b4921905a97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3467, 300), (1400, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "xtrain_w2v.shape, xtest_w2v.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA-7OMRMXuy4"
      },
      "source": [
        "### GLoVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oo3DCnfXv1Z",
        "outputId": "7929bd5e-7dee-42c0-8ee7-af0f9f0b8f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 19:01:11--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2023-03-22 19:01:12--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G   973KB/s    in 6m 5s   \n",
            "\n",
            "2023-03-22 19:07:18 (3.97 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.twitter.27B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izCBlMZZUMO8",
        "outputId": "03b05a45-00ec-41d0-85b5-ca1189e8762e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.twitter.27B.zip.1\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl5AeaOX4B4k"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_FILE = './glove.twitter.27B.200d.txt'\n",
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGK2h1ILxUQH"
      },
      "outputs": [],
      "source": [
        "x_train = df['tweet'].values\n",
        "y_train = df['sarcastic'].values\n",
        "x_test = df_test['text'].values\n",
        "y_test = df_test['sarcastic'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezAlm2PMS7wv"
      },
      "outputs": [],
      "source": [
        "max_features = 35000\n",
        "maxlen = 200\n",
        "\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(tokenized_train, maxlen=maxlen)\n",
        "\n",
        "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(tokenized_test, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zneuuqFF4PAl",
        "outputId": "1b571296-08da-4431-9347-c0b8fd1bdef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3249: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ],
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "#change below line if computing normal stats is too slow\n",
        "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvm2rW3fYeyG",
        "outputId": "997b9735-a0c9-4c3a-fc12-5141463dc55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11386, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('embedding_matrix.npy', embedding_matrix)"
      ],
      "metadata": {
        "id": "PsMruEyVnKW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM with GloVe**"
      ],
      "metadata": {
        "id": "7_ZKQioKTXwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.models import Model\n",
        "\n",
        "vocab_len = len(word_index)\n",
        "emb_dim = 200\n",
        "\n",
        "embedding_layer = Embedding(vocab_len,\n",
        "                            maxlen,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                             trainable=False)\n",
        "\n",
        "#Bi-LSTM\n",
        "model = Sequential([\n",
        "    embedding_layer,\n",
        "    Bidirectional(LSTM(emb_dim, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(emb_dim,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "'''\n",
        "#LSTM\n",
        "model = Sequential([\n",
        "    embedding_layer,\n",
        "    LSTM(emb_dim, return_sequences=True),\n",
        "    Dropout(0.5),\n",
        "    LSTM(emb_dim,),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "'''\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#Option 2\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(vocab_len, emb_dim, input_len = maxlen, trainable = False, weights=[embedding_matrix]))\n",
        "lstm_model.add(LSTM(128, return_sequences=False))\n",
        "lstm_model.add(Dropout(0.5))\n",
        "lstm_model.add(Dense(1, activation = 'sigmoid'))\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(lstm_model.summary())\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "Rzqx3ll2TXe-",
        "outputId": "eb7d8840-3b44-472e-91ce-df2da5d1fc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 200)          2277200   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 200, 400)         641600    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200, 400)          0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 400)              961600    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,880,801\n",
            "Trainable params: 1,603,601\n",
            "Non-trainable params: 2,277,200\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n#Option 2\\n\\nlstm_model = Sequential()\\nlstm_model.add(Embedding(vocab_len, emb_dim, input_len = maxlen, trainable = False, weights=[embedding_matrix]))\\nlstm_model.add(LSTM(128, return_sequences=False))\\nlstm_model.add(Dropout(0.5))\\nlstm_model.add(Dense(1, activation = 'sigmoid'))\\nlstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\nprint(lstm_model.summary())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64, epochs=10)#, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhlYoFPT24id",
        "outputId": "b3c7c9a3-62a0-4bdc-8d8d-cde9b007a34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "55/55 [==============================] - 42s 76ms/step - loss: 0.5815 - accuracy: 0.7456\n",
            "Epoch 2/10\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5615 - accuracy: 0.7505\n",
            "Epoch 3/10\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5419 - accuracy: 0.7511\n",
            "Epoch 4/10\n",
            "55/55 [==============================] - 4s 75ms/step - loss: 0.5230 - accuracy: 0.7603\n",
            "Epoch 5/10\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.5005 - accuracy: 0.7690\n",
            "Epoch 6/10\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4685 - accuracy: 0.7871\n",
            "Epoch 7/10\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.4182 - accuracy: 0.8105\n",
            "Epoch 8/10\n",
            "55/55 [==============================] - 4s 77ms/step - loss: 0.3482 - accuracy: 0.8431\n",
            "Epoch 9/10\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.3041 - accuracy: 0.8702\n",
            "Epoch 10/10\n",
            "55/55 [==============================] - 4s 76ms/step - loss: 0.2340 - accuracy: 0.8973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y6L81sAcT8n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred1 = [1 if prob > 0.5 else 0 for prob in y_pred]\n",
        "\n",
        "# Print f1, precision, and recall scores\n",
        "print(precision_score(y_test, y_pred1 , average=\"macro\"))\n",
        "print(recall_score(y_test, y_pred1 , average=\"macro\"))\n",
        "print(f1_score(y_test, y_pred1 , average=\"binary\"))\n",
        "print(confusion_matrix(y_pred1, y_test))\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz2FRcsqT8h7",
        "outputId": "90f7cd8d-127b-431a-a88d-0215f5618264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 1s 23ms/step\n",
            "0.5429434131066876\n",
            "0.52\n",
            "0.13333333333333333\n",
            "[[1134  181]\n",
            " [  66   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.94      0.90      1200\n",
            "           1       0.22      0.10      0.13       200\n",
            "\n",
            "    accuracy                           0.82      1400\n",
            "   macro avg       0.54      0.52      0.52      1400\n",
            "weighted avg       0.77      0.82      0.79      1400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bidirectional GRUs with Attention**"
      ],
      "metadata": {
        "id": "AVmI5XqbZOk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.supports_masking = True\n",
        "        self.init = keras.initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = keras.regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = keras.regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = keras.constraints.get(W_constraint)\n",
        "        self.b_constraint = keras.constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        \n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape = (input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape = (input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "        \n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    \n",
        "    def call(self, x, mask=None):\n",
        "        # TF backend doesn't support it\n",
        "        # eij = K.dot(x, self.W) \n",
        "        # features_dim = self.W.shape[0]\n",
        "        # step_dim = x._keras_shape[1]\n",
        "\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), \n",
        "                              K.reshape(self.W, (features_dim, 1))),\n",
        "                        (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        \n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'step_dim': self.step_dim}\n",
        "        base_config = super(AttentionLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "k8dueRw3b3lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_DIM = 128\n",
        "\n",
        "inp = keras.layers.Input(shape=(maxlen,))\n",
        "x = keras.layers.Embedding(vocab_len, emb_dim, trainable=True)(inp)\n",
        "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(GRU_DIM, return_sequences=True))(x)\n",
        "x = AttentionLayer(maxlen)(x)\n",
        "x = keras.layers.Dense(GRU_DIM*2, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "x = keras.layers.Dense(GRU_DIM, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "\n",
        "outp = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=inp, outputs=outp)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJfnWLXLT8WU",
        "outputId": "3bffc8c5-87bc-43aa-c432-a38c82a7497e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 200, 200)          2277200   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 200, 256)         253440    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " attention_layer_2 (Attentio  (None, 256)              456       \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,629,913\n",
            "Trainable params: 2,629,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=64, epochs=10)#, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "kFGBMJg0T8Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4ce529-3ec7-45e9-8707-5a4df6577df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "55/55 [==============================] - 8s 24ms/step - loss: 0.5785 - accuracy: 0.7395\n",
            "Epoch 2/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.5632 - accuracy: 0.7499\n",
            "Epoch 3/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.5253 - accuracy: 0.7609\n",
            "Epoch 4/10\n",
            "55/55 [==============================] - 2s 27ms/step - loss: 0.3121 - accuracy: 0.8820\n",
            "Epoch 5/10\n",
            "55/55 [==============================] - 2s 28ms/step - loss: 0.2096 - accuracy: 0.9302\n",
            "Epoch 6/10\n",
            "55/55 [==============================] - 1s 24ms/step - loss: 0.1038 - accuracy: 0.9691\n",
            "Epoch 7/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.0506 - accuracy: 0.9859\n",
            "Epoch 8/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.0273 - accuracy: 0.9931\n",
            "Epoch 9/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.0276 - accuracy: 0.9951\n",
            "Epoch 10/10\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.0204 - accuracy: 0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred1 = [1 if prob > 0.5 else 0 for prob in y_pred]\n",
        "\n",
        "print(f1_score(y_test, y_pred1 , average=\"binary\"))\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "id": "yB-2xDu4T79o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129ade45-5c85-4cf7-d5e2-a301f8934b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 1s 10ms/step\n",
            "0.264069264069264\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.85      1200\n",
            "           1       0.23      0.30      0.26       200\n",
            "\n",
            "    accuracy                           0.76      1400\n",
            "   macro avg       0.56      0.57      0.56      1400\n",
            "weighted avg       0.79      0.76      0.77      1400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stacked LSTM**"
      ],
      "metadata": {
        "id": "_veJQPTlyVQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_DIM = 128\n",
        "\n",
        "inp = keras.layers.Input(shape=(maxlen,))\n",
        "x = keras.layers.Embedding(vocab_len, emb_dim, trainable=True)(inp)\n",
        "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(LSTM_DIM*2, return_sequences=True))(x)\n",
        "x = keras.layers.Bidirectional(keras.layers.CuDNNGRU(LSTM_DIM, return_sequences=True))(x)\n",
        "x = AttentionLayer(maxlen)(x)\n",
        "x = keras.layers.Dense(LSTM_DIM*2, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "x = keras.layers.Dense(LSTM_DIM, activation='relu')(x)\n",
        "x = keras.layers.Dropout(rate=0.2)(x)\n",
        "\n",
        "outp = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model2 = keras.models.Model(inputs=inp, outputs=outp)\n",
        "    \n",
        "model2.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "fdCy0-WlyUZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(x_train, y_train, batch_size=64, epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuOkZUL7zvWp",
        "outputId": "ca4be77e-b863-44d8-f33c-b01b992a8b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "55/55 [==============================] - 6s 61ms/step - loss: 0.5747 - accuracy: 0.7416\n",
            "Epoch 2/7\n",
            "55/55 [==============================] - 3s 61ms/step - loss: 0.5684 - accuracy: 0.7499\n",
            "Epoch 3/7\n",
            "55/55 [==============================] - 3s 61ms/step - loss: 0.4576 - accuracy: 0.7894\n",
            "Epoch 4/7\n",
            "55/55 [==============================] - 3s 60ms/step - loss: 0.2250 - accuracy: 0.9233\n",
            "Epoch 5/7\n",
            "55/55 [==============================] - 3s 61ms/step - loss: 0.1039 - accuracy: 0.9738\n",
            "Epoch 6/7\n",
            "55/55 [==============================] - 3s 61ms/step - loss: 0.0618 - accuracy: 0.9847\n",
            "Epoch 7/7\n",
            "55/55 [==============================] - 3s 61ms/step - loss: 0.0595 - accuracy: 0.9873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred1 = [1 if prob > 0.5 else 0 for prob in y_pred]\n",
        "\n",
        "print(f1_score(y_test, y_pred1 , average=\"binary\"))\n",
        "print(classification_report(y_test, y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnhCO1SpzvM0",
        "outputId": "89c914f6-9eb0-45e2-9c63-e6496130f786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 0s 9ms/step\n",
            "0.27180527383367137\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84      1200\n",
            "           1       0.23      0.34      0.27       200\n",
            "\n",
            "    accuracy                           0.74      1400\n",
            "   macro avg       0.55      0.57      0.56      1400\n",
            "weighted avg       0.79      0.74      0.76      1400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVM with TF-IDF**"
      ],
      "metadata": {
        "id": "AwjlZTuOv6y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC \n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "clf = SVC(kernel='rbf', degree=3)\n",
        "clf.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "# predict and evaluate predictions\n",
        "y_pred_svm = clf.predict(xtest_tfidf)\n",
        "\n",
        "y_pred_svm1 = [1 if prob > 0.5 else 0 for prob in y_pred_svm]\n",
        "\n",
        "print(\"F1-Score: SVM with tfidf:\", f1_score(y_test, y_pred_svm1 , average=\"binary\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYo22g2kv-ih",
        "outputId": "21628fa1-7744-4091-a23c-d2e073f74b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: SVM with tfidf: 0.06140350877192982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fOllGSeYAlt"
      },
      "source": [
        "### Logistic Regression, Random Forest, XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJJuquPX6kla",
        "outputId": "7b72abb1-fa61-461f-c2e2-50a7e12c5f53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3467,), (1400,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "y_train = df['sarcastic'].values\n",
        "y_test = df_test['sarcastic'].values\n",
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ML Methods with Word2Vec**"
      ],
      "metadata": {
        "id": "TOqostknOo1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D_-NomJOi0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1762e4-1f37-4c27-a85c-fe66e3c4dcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: LR with Word2Vec: 0.0\n",
            "F1-Score: RF with Word2Vec: 0.047393364928909956\n",
            "F1-Score: XGB with Word2Vec: 0.09649122807017543\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,500,700], 'max_depth':[5,7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[300,500,700], \n",
        "                                         'max_depth':[5,7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "lr_model = lr.fit(xtrain_w2v, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_w2v, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_w2v, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_w2v)\n",
        "y_pred_rf = rf_model.predict(xtest_w2v)\n",
        "y_pred_xgb = xgb_model.predict(xtest_w2v)\n",
        "\n",
        "y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "y_pred_rf1 = [1 if prob > 0.5 else 0 for prob in y_pred_rf]\n",
        "y_pred_xgb1 = [1 if prob > 0.5 else 0 for prob in y_pred_xgb]\n",
        "\n",
        "print(\"F1-Score: LR with Word2Vec:\", f1_score(y_test, y_pred_lr1 , average=\"binary\"))\n",
        "print(\"F1-Score: RF with Word2Vec:\", f1_score(y_test, y_pred_rf1 , average=\"binary\"))\n",
        "print(\"F1-Score: XGB with Word2Vec:\", f1_score(y_test, y_pred_xgb1 , average=\"binary\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9QStlvNSIz4",
        "outputId": "99d8f2d3-fe42-4121-e282-4dd08ce48330"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 11, 'n_estimators': 700}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf_model.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcnrrpYGSPzq",
        "outputId": "e7eac2c7-d5f6-455f-bff5-b4a9428e6f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy RF: 0.845\n",
            "Accuracy LR: 0.856\n",
            "Accuracy XGB: 0.834\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPwRpqCpYE3v"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn import metrics\n",
        "from sklearn import utils\n",
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ML Methods with TFIDF**"
      ],
      "metadata": {
        "id": "CObX_TjdMMqT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUFUZhYTcRBY",
        "outputId": "dc295b7a-ca99-4888-e5d9-365d8c053fef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: LR with tfidf: 0.0\n",
            "F1-Score: RF with tfidf: 0.3682170542635659\n",
            "F1-Score: XGB with tfidf: 0.30466830466830463\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "                                         'max_depth':[7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_tfidf, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "y_pred_rf = rf_model.predict(xtest_tfidf)\n",
        "y_pred_xgb = xgb_model.predict(xtest_tfidf)\n",
        "\n",
        "#print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "#print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "#print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "\n",
        "y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "y_pred_rf1 = [1 if prob > 0.5 else 0 for prob in y_pred_rf]\n",
        "y_pred_xgb1 = [1 if prob > 0.5 else 0 for prob in y_pred_xgb]\n",
        "\n",
        "print(\"F1-Score: LR with tfidf:\", f1_score(y_test, y_pred_lr1 , average=\"binary\"))\n",
        "print(\"F1-Score: RF with tfidf:\", f1_score(y_test, y_pred_rf1 , average=\"binary\"))\n",
        "print(\"F1-Score: XGB with tfidf:\", f1_score(y_test, y_pred_xgb1 , average=\"binary\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_rf1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2NjsrobKj47",
        "outputId": "7077b6f3-339b-49a4-afce-cd2ade7b4fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.82      0.86      1200\n",
            "           1       0.30      0.47      0.37       200\n",
            "\n",
            "    accuracy                           0.77      1400\n",
            "   macro avg       0.60      0.65      0.61      1400\n",
            "weighted avg       0.82      0.77      0.79      1400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "#rf = RandomForestClassifier(class_weight='balanced_subsample', max_depth=11, n_estimators=300)\n",
        "\n",
        "xgb_classifier = XGBClassifier(max_depth=11, n_estimators=500)\n",
        "#grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "#                                        'max_depth':[7,11]})\n",
        "\n",
        "#lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "#lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "#rf.fit(xtrain_tfidf, y_train)\n",
        "xgb_classifier.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "#y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "#y_pred_rf = rf.predict(xtest_tfidf)\n",
        "y_pred_xgb = xgb_classifier.predict(xtest_tfidf)\n",
        "\n",
        "#print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "#print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "#print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "\n",
        "#y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "#y_pred_rf1 = [1 if prob > 0.5 else 0 for prob in y_pred_rf]\n",
        "y_pred_xgb1 = [1 if prob > 0.5 else 0 for prob in y_pred_xgb]\n",
        "\n",
        "#print(\"F1-Score: LR with tfidf:\", f1_score(y_test, y_pred_lr1 , average=\"binary\"))\n",
        "#print(\"F1-Score: RF with tfidf:\", f1_score(y_test, y_pred_rf1 , average=\"binary\"))\n",
        "print(\"F1-Score: XGB with tfidf:\", f1_score(y_test, y_pred_xgb1 , average=\"binary\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxqEb8MwYr9f",
        "outputId": "2beb14a6-d8db-49b9-865a-f494440d0a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: XGB with tfidf: 0.27895981087470445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_rf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3n7TMaQaaQv",
        "outputId": "6cd9a79c-c9c2-4c8b-d8ae-ec99499e3295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 11, 'n_estimators': 300}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ML Methods with BOW**"
      ],
      "metadata": {
        "id": "T8395m1RMHcn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLUvD9dFc1wd",
        "outputId": "7af2fa20-e8fd-4d20-d69f-e4a4e3cf7a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: LR with BOW: 0.03902439024390244\n",
            "F1-Score: RF with BOW: 0.3605313092979127\n",
            "F1-Score: XGB with BOW: 0.3064935064935065\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "                                         'max_depth':[7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "lr_model = lr.fit(xtrain_bow, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_bow, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_bow, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_bow)\n",
        "y_pred_rf = rf_model.predict(xtest_bow)\n",
        "y_pred_xgb = xgb_model.predict(xtest_bow)\n",
        "\n",
        "#print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "#print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "#print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "y_pred_lr1 = [1 if prob > 0.5 else 0 for prob in y_pred_lr]\n",
        "y_pred_rf1 = [1 if prob > 0.5 else 0 for prob in y_pred_rf]\n",
        "y_pred_xgb1 = [1 if prob > 0.5 else 0 for prob in y_pred_xgb]\n",
        "\n",
        "print(\"F1-Score: LR with BOW:\", f1_score(y_test, y_pred_lr1 , average=\"binary\"))\n",
        "print(\"F1-Score: RF with BOW:\", f1_score(y_test, y_pred_rf1 , average=\"binary\"))\n",
        "print(\"F1-Score: XGB with BOW:\", f1_score(y_test, y_pred_xgb1 , average=\"binary\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s7pf1FxNM_UN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j3cqauTxvBu6",
        "mCXI6bIGX0LZ",
        "wMNZS6rrXpt8",
        "DA-7OMRMXuy4",
        "TOqostknOo1D",
        "CObX_TjdMMqT",
        "T8395m1RMHcn"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}