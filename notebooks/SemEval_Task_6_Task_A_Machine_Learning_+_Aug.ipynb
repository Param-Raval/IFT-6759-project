{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "oP4GPyJVezV8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MIxB-54DLoi1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch and Load Data"
      ],
      "metadata": {
        "id": "TBvj3lgGe1s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/train/train.En.csv\n",
        "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/test/task_A_En_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJm8RW9rC6WY",
        "outputId": "fb08493b-d27c-4629-a1a3-4d513128efda"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-29 23:49:32--  https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/train/train.En.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491395 (480K) [text/plain]\n",
            "Saving to: ‘train.En.csv’\n",
            "\n",
            "train.En.csv        100%[===================>] 479.88K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-04-29 23:49:33 (12.7 MB/s) - ‘train.En.csv’ saved [491395/491395]\n",
            "\n",
            "--2023-04-29 23:49:33--  https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/test/task_A_En_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130890 (128K) [text/plain]\n",
            "Saving to: ‘task_A_En_test.csv’\n",
            "\n",
            "task_A_En_test.csv  100%[===================>] 127.82K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-04-29 23:49:33 (4.95 MB/s) - ‘task_A_En_test.csv’ saved [130890/130890]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "1nrllen0Lp_r",
        "outputId": "9e536781-94e0-424a-e33b-eb18a433bef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              tweet  sarcastic  \\\n",
              "0           0  The only thing I got from college is a caffein...          1   \n",
              "1           1  I love it when professors draw a big question ...          1   \n",
              "2           2  Remember the hundred emails from companies whe...          1   \n",
              "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
              "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
              "\n",
              "                                            rephrase  sarcasm  irony  satire  \\\n",
              "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
              "1  I do not like when professors don’t write out ...      1.0    0.0     0.0   \n",
              "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
              "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
              "4  I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0     0.0   \n",
              "\n",
              "   understatement  overstatement  rhetorical_question  \n",
              "0             0.0            0.0                  0.0  \n",
              "1             0.0            0.0                  0.0  \n",
              "2             0.0            0.0                  0.0  \n",
              "3             0.0            0.0                  0.0  \n",
              "4             0.0            0.0                  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1082be78-68e6-472a-9830-249608ea2a57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>rephrase</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "      <td>College is really difficult, expensive, tiring...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "      <td>I do not like when professors don’t write out ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1082be78-68e6-472a-9830-249608ea2a57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1082be78-68e6-472a-9830-249608ea2a57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1082be78-68e6-472a-9830-249608ea2a57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv('train.En.csv')\n",
        "df_test_taskA_en = pd.read_csv('task_A_En_test.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL_eUCz-LzX2",
        "outputId": "26f1c60a-2864-48d8-c87f-4809712d979f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3467, 10)\n",
            "(1400, 2)\n"
          ]
        }
      ],
      "source": [
        "# Removing rows where tweets are missing\n",
        "df=df.dropna(subset=['tweet'])\n",
        "df_test_taskA_en=df_test_taskA_en.dropna(subset=['text'])\n",
        "\n",
        "print(df.shape)\n",
        "print(df_test_taskA_en.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gGehbHTL1yQ",
        "outputId": "263f175e-2251-4487-9281-e410f65e1c66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2600\n",
              "1     867\n",
              "Name: sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['sarcastic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9u_0K7H8L-eI"
      },
      "outputs": [],
      "source": [
        "df_train, df_val = train_test_split(df, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Mutation for Data Augmentation\n",
        "Here, the setting order refers to the presence/absence of (remove, replace, shuffle) words in that order.\n",
        "\n",
        "Ex: the setting (0,1,0) means only the replace words operation is performed."
      ],
      "metadata": {
        "id": "a4smetscfOiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7Xvo17wGMAqw"
      },
      "outputs": [],
      "source": [
        "# import from mutant.py\n",
        "import mutant as mt\n",
        "aug=mt.TextMutant()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WzhHA7-tW40L"
      },
      "outputs": [],
      "source": [
        "data_aug = aug.create_new_dataset(df_train, [\"0\",\"1\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_010.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"0\",\"0\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_001.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"1\",\"0\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_100.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"0\",\"1\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_011.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"1\",\"1\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_110.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"1\",\"0\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_101.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train, [\"1\",\"1\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_111.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "V13OAPPu0gAY",
        "outputId": "0460dc15-c332-4830-b1b3-2d2793a487e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-32ca7a2a0631>:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df_train_aug_001 = df_train[[\"tweet\",\"sarcastic\"]].append(mut001[[\"tweet\",\"sarcastic\"]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  tweet  sarcastic\n",
              "1518  my mom says i need to interact w actual ppl an...          0\n",
              "3183  if he’s:\\n- smooth talkin\\n- so rockin\\n- got ...          0\n",
              "1581  Is only 12 hours away from my first #raceforli...          0\n",
              "2922  My investments investing in me! Sit back and w...          0\n",
              "2833  Does anyone else get really freaked out when s...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-788d9935-6252-4511-8934-431c68f596a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1518</th>\n",
              "      <td>my mom says i need to interact w actual ppl an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3183</th>\n",
              "      <td>if he’s:\\n- smooth talkin\\n- so rockin\\n- got ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1581</th>\n",
              "      <td>Is only 12 hours away from my first #raceforli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2922</th>\n",
              "      <td>My investments investing in me! Sit back and w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2833</th>\n",
              "      <td>Does anyone else get really freaked out when s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-788d9935-6252-4511-8934-431c68f596a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-788d9935-6252-4511-8934-431c68f596a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-788d9935-6252-4511-8934-431c68f596a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "mut001=pd.read_csv(\"mutation_001.csv\")\n",
        "mut010=pd.read_csv(\"mutation_010.csv\")\n",
        "mut011=pd.read_csv(\"mutation_011.csv\")\n",
        "mut100=pd.read_csv(\"mutation_100.csv\")\n",
        "mut101=pd.read_csv(\"mutation_101.csv\")\n",
        "mut110=pd.read_csv(\"mutation_110.csv\")\n",
        "mut111=pd.read_csv(\"mutation_111.csv\")\n",
        "\n",
        "df_train_aug_001 = df_train[[\"tweet\",\"sarcastic\"]].append(mut001[[\"tweet\",\"sarcastic\"]])\n",
        "df_train_aug_001.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ggi1x5vaL7xt"
      },
      "outputs": [],
      "source": [
        "df_train_aug_001 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut001[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_010 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut010[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_011 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut011[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_100 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut100[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_101 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut101[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_110 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut110[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_111 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut111[[\"tweet\",\"sarcastic\"]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcFfnJ_0LviG",
        "outputId": "4f326223-d30a-41d4-e245-80d83909395e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4210\n",
              "1    1336\n",
              "Name: sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_train_aug_111.sarcastic.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHErGQrgKjA7",
        "outputId": "1026af58-7911-4c04-c098-daccc99e99f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZzFi4fsuPknb"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn import metrics, utils\n",
        "import sklearn\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb \n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WYoG5zPtQD26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e423a6-e99e-448e-d967-41f827bcbea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutation: 0\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.677\n",
            "\tVal Accuracy LR: 0.723\n",
            "\tVal Accuracy XGB: 0.696\n",
            "\tVal F1 score RF: 0.353\n",
            "\tVal F1 score LR: 0.25\n",
            "\tVal F1 score XGB: 0.265\n",
            "\tTest Accuracy RF: 0.774\n",
            "\tTest Accuracy LR: 0.795\n",
            "\tTest Accuracy XGB: 0.793\n",
            "\tTest F1 score RF: 0.368\n",
            "\tTest F1 score LR: 0.178\n",
            "\tTest F1 score XGB: 0.233\n",
            "Mutation: 1\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.656\n",
            "\tVal Accuracy LR: 0.705\n",
            "\tVal Accuracy XGB: 0.7\n",
            "\tVal F1 score RF: 0.356\n",
            "\tVal F1 score LR: 0.244\n",
            "\tVal F1 score XGB: 0.297\n",
            "\tTest Accuracy RF: 0.75\n",
            "\tTest Accuracy LR: 0.811\n",
            "\tTest Accuracy XGB: 0.792\n",
            "\tTest F1 score RF: 0.357\n",
            "\tTest F1 score LR: 0.205\n",
            "\tTest F1 score XGB: 0.24\n",
            "Mutation: 2\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.657\n",
            "\tVal Accuracy LR: 0.702\n",
            "\tVal Accuracy XGB: 0.68\n",
            "\tVal F1 score RF: 0.32\n",
            "\tVal F1 score LR: 0.247\n",
            "\tVal F1 score XGB: 0.26\n",
            "\tTest Accuracy RF: 0.794\n",
            "\tTest Accuracy LR: 0.799\n",
            "\tTest Accuracy XGB: 0.785\n",
            "\tTest F1 score RF: 0.385\n",
            "\tTest F1 score LR: 0.23\n",
            "\tTest F1 score XGB: 0.285\n",
            "Mutation: 3\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.666\n",
            "\tVal Accuracy LR: 0.67\n",
            "\tVal Accuracy XGB: 0.673\n",
            "\tVal F1 score RF: 0.337\n",
            "\tVal F1 score LR: 0.312\n",
            "\tVal F1 score XGB: 0.27\n",
            "\tTest Accuracy RF: 0.795\n",
            "\tTest Accuracy LR: 0.753\n",
            "\tTest Accuracy XGB: 0.784\n",
            "\tTest F1 score RF: 0.406\n",
            "\tTest F1 score LR: 0.27\n",
            "\tTest F1 score XGB: 0.263\n",
            "Mutation: 4\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.666\n",
            "\tVal Accuracy LR: 0.723\n",
            "\tVal Accuracy XGB: 0.697\n",
            "\tVal F1 score RF: 0.359\n",
            "\tVal F1 score LR: 0.262\n",
            "\tVal F1 score XGB: 0.286\n",
            "\tTest Accuracy RF: 0.757\n",
            "\tTest Accuracy LR: 0.813\n",
            "\tTest Accuracy XGB: 0.791\n",
            "\tTest F1 score RF: 0.366\n",
            "\tTest F1 score LR: 0.234\n",
            "\tTest F1 score XGB: 0.251\n",
            "Mutation: 5\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n",
            "\tVal Accuracy RF: 0.656\n",
            "\tVal Accuracy LR: 0.7\n",
            "\tVal Accuracy XGB: 0.687\n",
            "\tVal F1 score RF: 0.334\n",
            "\tVal F1 score LR: 0.206\n",
            "\tVal F1 score XGB: 0.244\n",
            "\tTest Accuracy RF: 0.746\n",
            "\tTest Accuracy LR: 0.812\n",
            "\tTest Accuracy XGB: 0.809\n",
            "\tTest F1 score RF: 0.35\n",
            "\tTest F1 score LR: 0.255\n",
            "\tTest F1 score XGB: 0.239\n",
            "Mutation: 6\n",
            "(5546, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.682\n",
            "\tVal Accuracy LR: 0.653\n",
            "\tVal Accuracy XGB: 0.676\n",
            "\tVal F1 score RF: 0.363\n",
            "\tVal F1 score LR: 0.387\n",
            "\tVal F1 score XGB: 0.286\n",
            "\tTest Accuracy RF: 0.783\n",
            "\tTest Accuracy LR: 0.669\n",
            "\tTest Accuracy XGB: 0.775\n",
            "\tTest F1 score RF: 0.385\n",
            "\tTest F1 score LR: 0.269\n",
            "\tTest F1 score XGB: 0.222\n"
          ]
        }
      ],
      "source": [
        "tokens_val = df_val['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_test = df_test_taskA_en['text'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "\n",
        "y_val = df_val[\"sarcastic\"].values\n",
        "y_test = df_test_taskA_en['sarcastic'].values\n",
        " \n",
        "dataaug_list = [df_train_aug_110, df_train_aug_111, df_train_aug_101,\n",
        "                df_train_aug_100, df_train_aug_011, df_train_aug_010, \n",
        "                df_train_aug_001]\n",
        "\n",
        "for idx, df_curr in enumerate(dataaug_list):\n",
        "  print(f'Mutation: {idx}')\n",
        "  \n",
        "  tokens_train = df_curr['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "\n",
        "  tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "  xtrain_tfidf = tfidf_vectorizer.fit_transform(tokens_train)  \n",
        "  xval_tfidf = tfidf_vectorizer.transform(tokens_val)\n",
        "  xtest_tfidf= tfidf_vectorizer.transform(tokens_test)\n",
        "\n",
        "  print(xtrain_tfidf.shape, xval_tfidf.shape, xtest_tfidf.shape)\n",
        "\n",
        "  y_train = df_curr['sarcastic'].values\n",
        "  \n",
        "  rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "  grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "  xgb_classifier = XGBClassifier()\n",
        "  grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "                                          'max_depth':[7,11]})\n",
        "\n",
        "  lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "  lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "  rf_model = grid_rf.fit(xtrain_tfidf, y_train)\n",
        "  xgb_model = grid_xgb.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "  y_pred_lr = lr_model.predict(xval_tfidf)\n",
        "  y_pred_rf = rf_model.predict(xval_tfidf)\n",
        "  y_pred_xgb = xgb_model.predict(xval_tfidf)\n",
        "\n",
        "  print(f'\\tVal Accuracy RF: {round(np.mean(y_pred_rf==y_val), 3)}')\n",
        "  print(f'\\tVal Accuracy LR: {round(np.mean(y_pred_lr==y_val), 3)}')\n",
        "  print(f'\\tVal Accuracy XGB: {round(np.mean(y_pred_xgb==y_val), 3)}')\n",
        "\n",
        "  print(f'\\tVal F1 score RF: {round(f1_score(y_val, y_pred_rf), 3)}')\n",
        "  print(f'\\tVal F1 score LR: {round(f1_score(y_val, y_pred_lr), 3)}')\n",
        "  print(f'\\tVal F1 score XGB: {round(f1_score(y_val, y_pred_xgb), 3)}')\n",
        "\n",
        "  y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "  y_pred_rf = rf_model.predict(xtest_tfidf)\n",
        "  y_pred_xgb = xgb_model.predict(xtest_tfidf)\n",
        "\n",
        "  print(f'\\tTest Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "  print(f'\\tTest Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "  print(f'\\tTest Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "  print(f'\\tTest F1 score RF: {round(f1_score(y_test, y_pred_rf), 3)}')\n",
        "  print(f'\\tTest F1 score LR: {round(f1_score(y_test, y_pred_lr), 3)}')\n",
        "  print(f'\\tTest F1 score XGB: {round(f1_score(y_test, y_pred_xgb), 3)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation Balanced"
      ],
      "metadata": {
        "id": "RA3XAladkQFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"0\",\"1\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_010_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"0\",\"0\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_001_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"1\",\"0\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_100_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"0\",\"1\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_011_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"1\",\"1\",\"0\"])\n",
        "data_aug.to_csv(\"mutation_110_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"1\",\"0\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_101_sarcastic.csv\")\n",
        "data_aug = aug.create_new_dataset(df_train[df_train['sarcastic']==1], [\"1\",\"1\",\"1\"])\n",
        "data_aug.to_csv(\"mutation_111_sarcastic.csv\")"
      ],
      "metadata": {
        "id": "FL0m9RV_kFPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mut001=pd.read_csv(\"mutation_001_sarcastic.csv\")\n",
        "mut010=pd.read_csv(\"mutation_010_sarcastic.csv\")\n",
        "mut011=pd.read_csv(\"mutation_011_sarcastic.csv\")\n",
        "mut100=pd.read_csv(\"mutation_100_sarcastic.csv\")\n",
        "mut101=pd.read_csv(\"mutation_101_sarcastic.csv\")\n",
        "mut110=pd.read_csv(\"mutation_110_sarcastic.csv\")\n",
        "mut111=pd.read_csv(\"mutation_111_sarcastic.csv\")"
      ],
      "metadata": {
        "id": "KvvnaDT1kTae"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_aug_001 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut001[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_010 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut010[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_011 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut011[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_100 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut100[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_101 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut101[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_110 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut110[[\"tweet\",\"sarcastic\"]]))\n",
        "df_train_aug_111 = pd.concat((df_train[[\"tweet\",\"sarcastic\"]], mut111[[\"tweet\",\"sarcastic\"]]))"
      ],
      "metadata": {
        "id": "jABtZ6_mkTTQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_aug_111.sarcastic.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJpfoUPlkgJV",
        "outputId": "f45c93fa-26d6-4638-859e-c073f8745396"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2105\n",
              "1    1336\n",
              "Name: sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_val = df_val['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_test = df_test_taskA_en['text'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "\n",
        "y_val = df_val[\"sarcastic\"].values\n",
        "y_test = df_test_taskA_en['sarcastic'].values\n",
        " \n",
        "dataaug_list = [df_train_aug_110, df_train_aug_111, df_train_aug_101,\n",
        "                df_train_aug_100, df_train_aug_011, df_train_aug_010, \n",
        "                df_train_aug_001]\n",
        "\n",
        "for idx, df_curr in enumerate(dataaug_list):\n",
        "  print(f'Mutation: {idx}')\n",
        "  \n",
        "  tokens_train = df_curr['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "\n",
        "  tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "  xtrain_tfidf = tfidf_vectorizer.fit_transform(tokens_train)  \n",
        "  xval_tfidf = tfidf_vectorizer.transform(tokens_val)\n",
        "  xtest_tfidf= tfidf_vectorizer.transform(tokens_test)\n",
        "\n",
        "  print(xtrain_tfidf.shape, xval_tfidf.shape, xtest_tfidf.shape)\n",
        "\n",
        "  y_train = df_curr['sarcastic'].values\n",
        "  \n",
        "  rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "  grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "  xgb_classifier = XGBClassifier()\n",
        "  grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "                                          'max_depth':[7,11]})\n",
        "\n",
        "  lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "  lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "  rf_model = grid_rf.fit(xtrain_tfidf, y_train)\n",
        "  xgb_model = grid_xgb.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "  y_pred_lr = lr_model.predict(xval_tfidf)\n",
        "  y_pred_rf = rf_model.predict(xval_tfidf)\n",
        "  y_pred_xgb = xgb_model.predict(xval_tfidf)\n",
        "\n",
        "  print(f'\\tVal Accuracy RF: {round(np.mean(y_pred_rf==y_val), 3)}')\n",
        "  print(f'\\tVal Accuracy LR: {round(np.mean(y_pred_lr==y_val), 3)}')\n",
        "  print(f'\\tVal Accuracy XGB: {round(np.mean(y_pred_xgb==y_val), 3)}')\n",
        "\n",
        "  print(f'\\tVal F1 score RF: {round(f1_score(y_val, y_pred_rf), 3)}')\n",
        "  print(f'\\tVal F1 score LR: {round(f1_score(y_val, y_pred_lr), 3)}')\n",
        "  print(f'\\tVal F1 score XGB: {round(f1_score(y_val, y_pred_xgb), 3)}')\n",
        "\n",
        "  y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "  y_pred_rf = rf_model.predict(xtest_tfidf)\n",
        "  y_pred_xgb = xgb_model.predict(xtest_tfidf)\n",
        "\n",
        "  print(f'\\tTest Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "  print(f'\\tTest Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "  print(f'\\tTest Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "  print(f'\\tTest F1 score RF: {round(f1_score(y_test, y_pred_rf), 3)}')\n",
        "  print(f'\\tTest F1 score LR: {round(f1_score(y_test, y_pred_lr), 3)}')\n",
        "  print(f'\\tTest F1 score XGB: {round(f1_score(y_test, y_pred_xgb), 3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zZ1TlhBkgGA",
        "outputId": "8716378d-aa42-45aa-9bae-ebd9574ce1ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutation: 0\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.692\n",
            "\tVal Accuracy LR: 0.715\n",
            "\tVal Accuracy XGB: 0.663\n",
            "\tVal F1 score RF: 0.078\n",
            "\tVal F1 score LR: 0.124\n",
            "\tVal F1 score XGB: 0.32\n",
            "\tTest Accuracy RF: 0.844\n",
            "\tTest Accuracy LR: 0.832\n",
            "\tTest Accuracy XGB: 0.747\n",
            "\tTest F1 score RF: 0.167\n",
            "\tTest F1 score LR: 0.106\n",
            "\tTest F1 score XGB: 0.259\n",
            "Mutation: 1\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.699\n",
            "\tVal Accuracy LR: 0.712\n",
            "\tVal Accuracy XGB: 0.663\n",
            "\tVal F1 score RF: 0.14\n",
            "\tVal F1 score LR: 0.107\n",
            "\tVal F1 score XGB: 0.328\n",
            "\tTest Accuracy RF: 0.829\n",
            "\tTest Accuracy LR: 0.84\n",
            "\tTest Accuracy XGB: 0.736\n",
            "\tTest F1 score RF: 0.184\n",
            "\tTest F1 score LR: 0.138\n",
            "\tTest F1 score XGB: 0.242\n",
            "Mutation: 2\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.589\n",
            "\tVal Accuracy LR: 0.635\n",
            "\tVal Accuracy XGB: 0.643\n",
            "\tVal F1 score RF: 0.424\n",
            "\tVal F1 score LR: 0.363\n",
            "\tVal F1 score XGB: 0.371\n",
            "\tTest Accuracy RF: 0.538\n",
            "\tTest Accuracy LR: 0.677\n",
            "\tTest Accuracy XGB: 0.708\n",
            "\tTest F1 score RF: 0.259\n",
            "\tTest F1 score LR: 0.289\n",
            "\tTest F1 score XGB: 0.263\n",
            "Mutation: 3\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.581\n",
            "\tVal Accuracy LR: 0.634\n",
            "\tVal Accuracy XGB: 0.651\n",
            "\tVal F1 score RF: 0.421\n",
            "\tVal F1 score LR: 0.38\n",
            "\tVal F1 score XGB: 0.37\n",
            "\tTest Accuracy RF: 0.523\n",
            "\tTest Accuracy LR: 0.649\n",
            "\tTest Accuracy XGB: 0.708\n",
            "\tTest F1 score RF: 0.256\n",
            "\tTest F1 score LR: 0.27\n",
            "\tTest F1 score XGB: 0.274\n",
            "Mutation: 4\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.7\n",
            "\tVal Accuracy LR: 0.702\n",
            "\tVal Accuracy XGB: 0.669\n",
            "\tVal F1 score RF: 0.103\n",
            "\tVal F1 score LR: 0.321\n",
            "\tVal F1 score XGB: 0.299\n",
            "\tTest Accuracy RF: 0.844\n",
            "\tTest Accuracy LR: 0.762\n",
            "\tTest Accuracy XGB: 0.73\n",
            "\tTest F1 score RF: 0.167\n",
            "\tTest F1 score LR: 0.227\n",
            "\tTest F1 score XGB: 0.244\n",
            "Mutation: 5\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.706\n",
            "\tVal Accuracy LR: 0.686\n",
            "\tVal Accuracy XGB: 0.682\n",
            "\tVal F1 score RF: 0.038\n",
            "\tVal F1 score LR: 0.278\n",
            "\tVal F1 score XGB: 0.336\n",
            "\tTest Accuracy RF: 0.843\n",
            "\tTest Accuracy LR: 0.763\n",
            "\tTest Accuracy XGB: 0.749\n",
            "\tTest F1 score RF: 0.06\n",
            "\tTest F1 score LR: 0.213\n",
            "\tTest F1 score XGB: 0.248\n",
            "Mutation: 6\n",
            "(3441, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVal Accuracy RF: 0.651\n",
            "\tVal Accuracy LR: 0.618\n",
            "\tVal Accuracy XGB: 0.671\n",
            "\tVal F1 score RF: 0.363\n",
            "\tVal F1 score LR: 0.355\n",
            "\tVal F1 score XGB: 0.325\n",
            "\tTest Accuracy RF: 0.744\n",
            "\tTest Accuracy LR: 0.65\n",
            "\tTest Accuracy XGB: 0.762\n",
            "\tTest F1 score RF: 0.37\n",
            "\tTest F1 score LR: 0.26\n",
            "\tTest F1 score XGB: 0.281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htEOvZinkgB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Augmentation"
      ],
      "metadata": {
        "id": "0OImfWwilL7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MgKMl_3KU0eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abb54b0-37d6-4ada-ff17-08285baa9734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2773, 1000) (694, 1000) (1400, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy RF: 0.677\n",
            "Accuracy LR: 0.713\n",
            "Accuracy XGB: 0.686\n",
            "F1 score RF: 0.345\n",
            "F1 score LR: 0.0\n",
            "F1 score XGB: 0.273\n",
            "Accuracy RF: 0.781\n",
            "Accuracy LR: 0.857\n",
            "Accuracy XGB: 0.8\n",
            "F1 score RF: 0.376\n",
            "F1 score LR: 0.0\n",
            "F1 score XGB: 0.271\n"
          ]
        }
      ],
      "source": [
        "df_train_without_aug = df_train[[\"tweet\",\"sarcastic\"]]\n",
        "tokens_train = df_train_without_aug['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_val = df_val['tweet'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "tokens_test = df_test_taskA_en['text'].apply(lambda x: ' '.join([val for val in word_tokenize(x.lower()) if val not in stop_words])).values\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
        "xtrain_tfidf = tfidf_vectorizer.fit_transform(tokens_train)\n",
        "xval_tfidf = tfidf_vectorizer.transform(tokens_val)\n",
        "xtest_tfidf= tfidf_vectorizer.transform(tokens_test)\n",
        "\n",
        "print(xtrain_tfidf.shape, xval_tfidf.shape, xtest_tfidf.shape)\n",
        "\n",
        "y_train = df_train_without_aug['sarcastic'].values\n",
        "y_val = df_val[\"sarcastic\"].values\n",
        "y_test = df_test_taskA_en['sarcastic'].values\n",
        "y_train.shape, y_val.shape, y_test.shape\n",
        "\n",
        "rf = RandomForestClassifier(class_weight='balanced_subsample')\n",
        "grid_rf = GridSearchCV(rf, {'n_estimators':[300,700], 'max_depth':[7,11]})\n",
        "\n",
        "xgb_classifier = XGBClassifier()\n",
        "grid_xgb = GridSearchCV(xgb_classifier, {'n_estimators':[500,700], \n",
        "                                         'max_depth':[7,11]})\n",
        "\n",
        "lr = LogisticRegressionCV(max_iter=1000)\n",
        "\n",
        "lr_model = lr.fit(xtrain_tfidf, y_train)\n",
        "rf_model = grid_rf.fit(xtrain_tfidf, y_train)\n",
        "xgb_model = grid_xgb.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(xval_tfidf)\n",
        "y_pred_rf = rf_model.predict(xval_tfidf)\n",
        "y_pred_xgb = xgb_model.predict(xval_tfidf)\n",
        "\n",
        "print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_val), 3)}')\n",
        "print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_val), 3)}')\n",
        "print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_val), 3)}')\n",
        "\n",
        "print(f'F1 score RF: {round(f1_score(y_val, y_pred_rf), 3)}')\n",
        "print(f'F1 score LR: {round(f1_score(y_val, y_pred_lr), 3)}')\n",
        "print(f'F1 score XGB: {round(f1_score(y_val, y_pred_xgb), 3)}')\n",
        "\n",
        "y_pred_lr = lr_model.predict(xtest_tfidf)\n",
        "y_pred_rf = rf_model.predict(xtest_tfidf)\n",
        "y_pred_xgb = xgb_model.predict(xtest_tfidf)\n",
        "\n",
        "print(f'Accuracy RF: {round(np.mean(y_pred_rf==y_test), 3)}')\n",
        "print(f'Accuracy LR: {round(np.mean(y_pred_lr==y_test), 3)}')\n",
        "print(f'Accuracy XGB: {round(np.mean(y_pred_xgb==y_test), 3)}')\n",
        "\n",
        "print(f'F1 score RF: {round(f1_score(y_test, y_pred_rf), 3)}')\n",
        "print(f'F1 score LR: {round(f1_score(y_test, y_pred_lr), 3)}')\n",
        "print(f'F1 score XGB: {round(f1_score(y_test, y_pred_xgb), 3)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhhW6xBIVvSC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}